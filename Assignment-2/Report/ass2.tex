% More info on this class can be found on: http://www.ctan.org/pkg/paper.
\documentclass[12pt,a4paper,oneside]{paper} % Accepts option `twocolumn`.
%\usepackage{fullpage} % If needed.
\usepackage{lmodern} % Fonts. Needed somehow, otherwise things break.
\usepackage[english]{babel} % English language/hyphenation.
\usepackage[T1]{fontenc} % Use 8-bit output encoding.
\usepackage[utf8]{inputenc} % Can use UTF-8 in the source files.
\usepackage[babel]{microtype} % Improves appearance of text.
\usepackage{url}
\usepackage{csquotes}
\usepackage{float}
\usepackage[]{minted}
\usepackage{amsmath,amsthm, amssymb}
% Reference sheet: http://merkel.zoneo.net/Latex/natbib.php
% \usepackage{natbib} % Better references
% \bibliographystyle{abbrvnat}
% If possible, it is preferable to directly include PDF images.
\usepackage{graphicx}
\usepackage{multirow}
\graphicspath{{fig/}}
\usepackage{hyperref}
\hypersetup{
  colorlinks=false,
  pdfauthor={Gaurav Gupta},
  pdftitle={Assignment 2: Code for BFGS and GA}
}

%creates a new question command
\newcommand{\question}{%
    \stepcounter{section}% Increment the section counter
    \section*{Question \thesection}% Print "Question" followed by the updated section number
    \addcontentsline{toc}{section}{Question \thesection}% Optionally add to the table of contents
}

\newcommand{\variables}{%
    {\subsection{Decision Variables}} % Smaller font for subsection title
    \addcontentsline{toc}{subsection}{Decision Variables}
}

\newcommand{\constraints}{%
    {\subsection{Constraints}} % Smaller font for subsection title
    \addcontentsline{toc}{subsection}{Constraints}
}

\newcommand{\of}{%
    {\subsection{Objective Function}} % Smaller font for subsection title
    \addcontentsline{toc}{subsection}{Objective Function}
}

\newcommand{\sol}{%
    {\subsection{Solution}} % Smaller font for subsection title
    \addcontentsline{toc}{subsection}{Solution}
}

% Removes double spacing after end of sentence.
% See: http://practicaltypography.com/one-space-between-sentences.html.
\frenchspacing


\title{Assignment 2: Python Code for BFGS and GA}
\subtitle{AE413: Optimization techniques in engineering}
\author{Gaurav Gupta, SC21B026}

% Don't know how this is used. Removing it messes the header.
\shortauthor{Gaurav}
\shorttitle{Assignment 2}

\begin{document}
\maketitle

% \abstract{}

\section{Overview}

This report discusses the implementation and testing of two optimization algorithms: \textbf{BFGS (Broyden–Fletcher–Goldfarb–Shanno)} and \textbf{Genetic Algorithm (GA)} in python. Both algorithms serve different optimization needs, with BFGS being suitable for smooth, differentiable functions and GA being more flexible for complex, non-linear, and non-differentiable problems.

\subsection*{BFGS Algorithm}
BFGS is a quasi-Newton method used to find local minima of smooth functions. It approximates the Hessian matrix to iteratively update the search direction, making it efficient for problems where derivatives are available and relatively inexpensive to compute. The BFGS method is particularly well-suited for smooth, unimodal functions and is widely used in various scientific and engineering applications due to its convergence properties and computational efficiency.

\subsection*{Genetic Algorithm (GA)}
GA is an evolutionary algorithm inspired by the principles of natural selection and genetics. This implementation includes:
\begin{itemize}
    \item \textbf{Elitism-based selection}: Ensures the fittest individuals are carried over to the next generation.
    \item \textbf{Simulated Binary Crossover (SBX)}: Combines pairs of parents to produce offspring with a controlled level of diversity.
    \item \textbf{Normally Disturbed Mutation}: Introduces small variations in offspring to enhance exploration of the search space.
\end{itemize}
GA is particularly effective for global optimization, where the objective function may be non-linear, multi-modal, or non-differentiable.

\section{Benchmark Functions}

Two benchmark functions were used to evaluate the performance of BFGS and GA:

\begin{itemize}
    \item \textbf{Bohachevsky Function}: 
    \[
    f(x, y) = x^2 + 2y^2 - 0.3\cos(3\pi x) - 0.4\cos(4\pi y) + 0.7
    \]
    This unimodal function tests the algorithms' ability to converge to a global minimum in a smooth landscape.

    \item \textbf{Ackley Function}:
    \[
    f(x, y) = -20 \exp\left(-0.2 \sqrt{0.5(x^2 + y^2)}\right) - \exp\left(0.5(\cos(2\pi x) + \cos(2\pi y))\right) + 20 + \exp(1)
    \]
    Known for its numerous local minima, the Ackley function challenges the algorithms with a rugged, multimodal landscape.
\end{itemize}

\section{Results}

\subsection{Comparison between BFGS and GA}
\textbf{Table \ref{tab:pythonCode}} and \textbf{Table \ref{tab:matlabCode}} present the results from the Python implementation of BFGS and GA alongside the in-built MATLAB function of \emph{fminunc} and \emph{ga}. 
\begin{itemize}
    \item \textbf{The results of BFGS is highly dependent on the initial point of search.}\\
    For example, in case of the Ackley Multimodal benchmark the algorithm converges to a local minima when started from $(-5,5)$ whereas converges to a global minima when started from $(-0.1, 0.1)$.
    \item \textbf{GA is always converges in the neighbourhood of global minima.}\\
    In case of Ackley multimodal benchmark, the algorithm coverges to the same point which is very close to the global minima of $(0,0)$.
    \item The computational time is comparable for both algorithms in case of MATLAB functions whereas in current Python implementation, GA is slower than BFGS.
\end{itemize}

\begin{table}[H]
    \centering
    \begin{tabular}{|p{0.35\textwidth}|c|c|c|c|}
        \hline
        \multirow{2}{*}{\textbf{Benchmark Case}} & \multicolumn{2}{|c|}{\textbf{Point of Minima}} & \multicolumn{2}{c|}{\textbf{Computation Time (s)}} \\ \cline{2-5}
        & BFGS & GA & BFGS & GA \\ \hline
        Bohachevsky (Unimodal) & (0,0) & (0.133,-0.044) & 0.236 & 134.72\\ \hline
        Ackley (Local Minima) & (-4.986, 4.986) & (0.0484, -0.0418) & 0.239 & 445.23\\ \hline
        Ackley (Global Minima) & (0, 0) & (0.0484, -0.0418) & 0.549 & 445.23\\ \hline
    \end{tabular}
    \caption{Results from Python implementation of BFGS and GA}
    \label{tab:pythonCode}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|p{0.35\textwidth}|c|c|c|c|}
        \hline
        \multirow{2}{*}{\textbf{Benchmark Case}} & \multicolumn{2}{|c|}{\textbf{Point of Minima}} & \multicolumn{2}{c|}{\textbf{Computation Time (s)}} \\ \cline{2-5}
        & BFGS & GA & BFGS & GA \\ \hline
        Bohachevsky (Unimodal) & (0.618, 0) & (-0.007, -0.020) & 0.132 & 3.013\\ \hline
        Ackley (Local Minima) & (-4.986, 4.986) & (-0.020,0.010) & 0.0913 & 0.0583\\ \hline
        Ackley (Global Minima) & (0, 0) & (-0.020,0.010) & 0.0103 & 0.0583\\ \hline
    \end{tabular}
    \caption{Results from MATLAB using \emph{fminunc} (BFGS) and \emph{ga} functions.}
    \label{tab:matlabCode}
\end{table}

\subsection{Comparison between Python implementation and MATLAB}
\begin{itemize}
    \item Python implementation of BFGS and \emph{fminunc} perform almost equivalent. The solution is exact in all cases except for Unimodal case using \emph{fminunc}. Although, the \emph{fminunc} is slightly faster than Python implementation for all the cases.
    \item Python implementation of GA and \emph{ga} yield similar results but the MATLAB function is exceptionally fast as compared to the Python implementation. The \emph{ga} allows use of different kinds of crossover and mutation methods as compared to the fixed type of crossover and mutation in our code.
\end{itemize}

\section{Conclusion}
\noindent Based on the results from both the Python implementation and MATLAB functions, it is clear that BFGS works well for unimodal functions since it reliably converges to the global minimum. On the other hand, GA is better suited for complex multimodal functions due to its ability to explore and handle multiple minima effectively.

\section{Code Availability}
The code for the BFGS and Genetic Algorithm implementations, including tests on the Bohachevsky and Ackley functions, is available on GitHub at:  
\url{https://github.com/airwarriorg91/Optimization-Techniques/tree/main/Assignment-2}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \bibliography{paper} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}